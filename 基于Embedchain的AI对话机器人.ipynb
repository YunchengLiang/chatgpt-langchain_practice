{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iFbp62wyt_CM"
      },
      "source": [
        "# 基于Embedchain的AI对话机器人\n",
        "\n",
        "原理：基于大语言模型LLM，分别提取全书内容的Embedding，和输入问题的Embedding，查询匹配后输出回答语句。\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vFwOa5SSiHxZ"
      },
      "source": [
        "## 安装配置工具包"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip uninstall langchain pydantic typing-inspect typing_extensions keras protobuf tensorboard msrest torch -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install keras==2.11.0 protobuf==3.19 tensorboard==2.11 msrest==0.6.21 torch==2.0.0 langchain==0.0.217 pydantic==1.10.8 typing-inspect==0.8.0 typing_extensions==4.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip uninstall langchain pydantic typing-inspect typing_extensions -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain==0.0.217 pydantic==1.10.8 typing-inspect==0.8.0 typing_extensions==4.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --user embedchain"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "U1PSCyVZiHxa"
      },
      "source": [
        "## 大语言模型-开源免费\n",
        "\n",
        "参考文档：https://github.com/embedchain/embedchain#1-app-uses-openai-models-paid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### the default model of gpt4all is orca-mini-3b.ggmlv3.q4_0.bin 1.9GB    \n",
        "### currently the best one is nous-hermes-13b.ggmlv3.q4_0.bin https://gpt4all.io/index.html 6.8GB\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "embedchain and azure cognitive services have overlapping but some different integrations regarding input data format, like embedchain inherit youtube url as source from langchain and microsoft azure cognitive service supports ppt.     \n",
        "    \n",
        "Another thing is that gpt4all has multiple open source models and the default one embedchain is using is 1.9GB and the overall best one is about 6.8GB https://gpt4all.io/index.html, using it requires download the model, while using openai api though costs money, puts less burden on the compute instances' memory.    \n",
        "    \n",
        "Though both microsoft and embedchain supports html as input source. It actually better to convert the websites as pdf since the complicate design of the webUI do disturbs the quality of the content crawled from those sites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading open source embedding model. This may take some time...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30508dfd387a4ed7af952a9be12de8d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52fc9dabdd004ad6a71d5387da96c448",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a0faac7f6a94f2fac3be849e4645632",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34c3566a34f446089fd8805b71c55dc6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28dc85670f074b00aabe804344c55359",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40665cd2ac974b47b5d81b3bfd67e669",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3c647a009824d8f98f0270fdd8f5063",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4ac3aa5eb8d41958861fde232423893",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01c919c9f0b54531b0a57df968b559d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61fb2ae7162440d3a3f4c6220018de8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "569c2533c1434f60b8548f83d581f68a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3b6a30c91a4c4db2ac2f23a7560f0401",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "525a1000293b48b9993fa6fb9216036e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "70bdb67562674fa59b8f29ca8ec1f294",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully loaded open source embedding model.\n"
          ]
        }
      ],
      "source": [
        "# 开源免费大语言模型\n",
        "from embedchain import OpenSourceApp\n",
        "chat_bot = OpenSourceApp()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W9mC8H6huFPB"
      },
      "source": [
        "## 大语言模型-OpenAI付费API\n",
        "\n",
        "\n",
        "查看OpenAI API Key：https://platform.openai.com/account/api-keys"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "80P6dCfFiHxb"
      },
      "source": [
        "- 测试OpenAI API KEY可用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mMvBguaiHxb",
        "outputId": "d7d3acf6-72c3-4707-959a-7808e2ba2be8"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uc3pcGEhiHxb"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8A0qMKtJiHxb"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "openai.api_key = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgVqSs-uiHxb"
      },
      "outputs": [],
      "source": [
        "openai.Model.list()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9nPOXqDiHxc"
      },
      "source": [
        "- 实例化对话机器人"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su9OeC5q3o-r"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "from embedchain import App\n",
        "\n",
        "chat_bot = App()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oddGB_IJu_Pg"
      },
      "source": [
        "## 载入你自己的数据-PDF文档\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KCZ209M4vWzI"
      },
      "outputs": [],
      "source": [
        "# pdf_url = 'https://navalmanack.s3.amazonaws.com/Eric-Jorgenson_The-Almanack-of-Naval-Ravikant_Final.pdf'\n",
        "pdf_url = 'https://www.rogers.com/cms/pdf/en/Consumer_SUG_V20.pdf' #online resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnLrLNr6vXFY",
        "outputId": "ea67471e-499f-4027-fd74-26e2d31856b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved https://www.rogers.com/cms/pdf/en/Consumer_SUG_V20.pdf. Total chunks count: 55\n"
          ]
        }
      ],
      "source": [
        "chat_bot.add('pdf_file', pdf_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pdf_url_2 = 'C:/Users/87032/OneDrive/Documents/GitHub/chatgpt-langchain_practice/Yuncheng_Liang__resume.pdf'#local file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# chat_bot.add('pdf_file', pdf_url_2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kZ3DK5nBu_UO"
      },
      "source": [
        "## 载入你自己的数据-网页"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nt5q7mFewtaN"
      },
      "outputs": [],
      "source": [
        "webpage_url_1 = 'https://www.rogers.com/internet/wifi?icid=R_IGN_2II_VU0GP0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50amV0l_w81v",
        "outputId": "4a9c9cad-9049-4009-9f86-e6310b440ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully saved https://www.rogers.com/internet/wifi?icid=R_IGN_2II_VU0GP0. Total chunks count: 64\n"
          ]
        }
      ],
      "source": [
        "chat_bot.add('web_page', webpage_url_1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lr82BGCku_XJ"
      },
      "source": [
        "## 载入你自己的数据-QA问答对"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BGwQ16Gxai2",
        "outputId": "c443e245-6eef-407e-cbd4-d511b6c84d01"
      },
      "outputs": [],
      "source": [
        "# # 问题\n",
        "# Q = 'Who is Naval Ravikant?'\n",
        "\n",
        "# # 回答\n",
        "# A = 'Naval Ravikant is an Indian-American entrepreneur and investor.'\n",
        "\n",
        "# naval_chat_bot.add_local('qna_pair', (Q, A))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gWR17HZWt-or"
      },
      "source": [
        "## 载入你自己的数据-youtube视频\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-Luc7_uvFnD"
      },
      "outputs": [],
      "source": [
        "# youtube_video_url = 'https://www.youtube.com/watch?v=3qHkcs3kG44'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MiZHlLmvM8W",
        "outputId": "909515c3-22d0-490b-8732-df4776f50226"
      },
      "outputs": [],
      "source": [
        "# chat_bot.add('youtube_video', youtube_video_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "F1fPBJHIyE62"
      },
      "source": [
        "## 向对话机器人提问"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### without prompt engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7CzzdoxiHxg",
        "outputId": "3d25aef3-702c-4bbf-ae47-12dfaec93d55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.93G/1.93G [02:49<00:00, 11.4MiB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model downloaded at:  C:\\\\\\\\Users\\\\\\\\yuncheng.liang\\\\\\\\.cache\\\\\\\\gpt4all\\\\orca-mini-3b.ggmlv3.q4_0.bin\n",
            " To download ringtones from your mobile device, you can follow these steps:\n",
            "1. Open the Mobile Backup app or any other ringtone downloading app on your device.\n",
            "2. Select the Internet icon from your main menu. Then select the Shop link from your mobile internet home page or text MUSIC to 555 for a link to the Music and Tones page.\n",
            "3. Search for ringtones that you like, and then click on the Download link next to each ringtone.\n",
            "4. Once downloaded, an option will appear to set the new download as your default ringtone.\n"
          ]
        }
      ],
      "source": [
        "question = 'how to download ringtones?'\n",
        "answer = chat_bot.query(question)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8QjbEBMkgv4",
        "outputId": "546f0f28-0eec-4bb6-d8d8-8b57d4cc249b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " - Ignite InternetTM is backed by our WiFi Satisfaction Guarantee.\n"
          ]
        }
      ],
      "source": [
        "question = 'which services are backed by the ignite WiFi satisfaction guarantee?'\n",
        "answer = chat_bot.query(question)\n",
        "print(answer)\n",
        "#Our Ignite Internet packages and bundles featuring the Ignite WiFi Gateway modem are backed by the Ignite WiFi Satisfaction Guarantee."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIJPoif8kmk1",
        "outputId": "09c8e25f-cb61-460f-cfe5-971b54c43bf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " If you have a question about the Ignite WiFi Satisfaction Guarantee, you can contact our customer support team at 1-866-536-8243 or chat with us using the Ignite HomeConnect app.\n"
          ]
        }
      ],
      "source": [
        "question = 'which number should I call if I have question about the Ignite WiFi Satisfaction Guarantee?'\n",
        "answer = chat_bot.query(question)\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " If you need assistance with your Ignite WiFi, you can contact our support team through the Ignite HomeConnect app or by calling us at 1-866-536-8243. Our support team is available to help you 24/7 and can provide technical support, troubleshoot issues, and answer any questions you may have about your Ignite WiFi service.\n"
          ]
        }
      ],
      "source": [
        "question = 'How can you get help with my Ignite WiFi if you need it?'\n",
        "answer = chat_bot.query(question)\n",
        "print(answer)\n",
        "\n",
        "#The Ignite HomeConnect app offers instant troubleshooting tips and tools. You can restart your Ignite WiFi Gateway modem,test the connection for your device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### with prompt engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query:  which services are backed by the ignite WiFi satisfaction guarantee?\n",
            "Response:   Ignite Internet is backed by our WiFi Satisfaction Guarantee and we offer powerful WiFi technology for all your connected devices with the most powerful modems.\n",
            "Query:  which number should I call if I have question about the Ignite WiFi Satisfaction Guarantee?\n",
            "Response:   You can contact us at 1-866-536-8243 or see full details on our website.\n",
            "Query:  How can you get help with my Ignite WiFi if you need it?\n",
            "Response:   You can contact us through the Ignite HomeConnect app or by calling our customer support number at 1-866-536-8243. We are always here to assist you and help you with your Ignite WiFi!\n"
          ]
        }
      ],
      "source": [
        "from embedchain.config import QueryConfig\n",
        "from embedchain.embedchain import App\n",
        "from string import Template\n",
        "\n",
        "chatbot_template = Template(\"\"\"\n",
        "        You are a customer service agent of Rogers Communications which is a telecommunication company in Canada.\n",
        "        You are helpful and honest on answering customers' questions.  \n",
        "\n",
        "        Use the following information about Rogers Communications to respond to \n",
        "        the customer's query acting as a customer service agent.\n",
        "        Context: $context                                \n",
        "\n",
        "        Keep the response brief and only use the information given by the context. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "        Customer: $query\n",
        "        Customer service agent:\"\"\")\n",
        "query_config = QueryConfig(chatbot_template)\n",
        "queries = [\n",
        "        \"which services are backed by the ignite WiFi satisfaction guarantee?\",\n",
        "        \"which number should I call if I have question about the Ignite WiFi Satisfaction Guarantee?\",\n",
        "        \"How can you get help with my Ignite WiFi if you need it?\",\n",
        "]\n",
        "for query in queries:\n",
        "        response = chat_bot.query(query, query_config)\n",
        "        print(\"Query: \", query)\n",
        "        print(\"Response: \", response)\n",
        "#links\n",
        "#https://www.rogers.com/internet/wifi?icid=R_COR_JOR_4PDRJT\n",
        "#the phone number is different because the website shows different number from the element, see screen-shot in word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query:  how to download ringtones?\n",
            "Response:   To download a ringtone, follow these steps:\n",
            " 1. Select the Internet icon from your main menu. Then select the Shop link from your mobile internet home page or text MUSIC to 555 for a link to the Music and Tones page.\n",
            "2. Select Ringtones to check out categories such as Top Sellers and Spotlights.\n",
            "3. Select a ringtone, then click on the Download link. Once downloaded, an option will appear to set the new download as your ringtone.\n",
            "Query:  How are my services invoiced for the first bill?\n",
            "Response:   Your first bill includes partial charges and regular charges. Regular charges include your monthly plan and any add-on fees billed in advance for the next month. If you exceed monthly usage limits, extra charges will be listed on your next invoice in the “Regular Charges” section.\n"
          ]
        }
      ],
      "source": [
        "#see pdf Consumer_SUG_V20.pdf\n",
        "queries = [\n",
        "        \"how to download ringtones?\",\n",
        "        \"How are my services invoiced for the first bill?\"\n",
        "]\n",
        "for query in queries:\n",
        "        response = chat_bot.query(query, query_config)\n",
        "        print(\"Query: \", query)\n",
        "        print(\"Response: \", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Your first bill includes partial charges and regular charges. Regular charges include your monthly\n",
        "#plan and any add-on fees billed in advance for the next month. If you exceed monthly usage limits, \n",
        "#extra charges will be listed on your next invoice in the “Regular Charges” section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### potential problems with websites that needs authentification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading open source embedding model. This may take some time...\n",
            "Successfully loaded open source embedding model.\n",
            "Successfully saved https://rogers2.service-now.com/hrportal?id=dynamic_hr_article&sys_id=5e99629a1b8701104cd7a8a8b04bcb2e. Total chunks count: 1\n",
            "Successfully saved https://www.rogerszone.ca/en-ca/ourrogers/DiscountsOffers/Pages/Legacy-Shaw-Employee-Account-Program.aspx. Total chunks count: 2\n",
            "Query:  During the enrollment period of the Flex Benefits, what do I need to do?\n",
            "Response:   To enroll in Flex Benefits during the enrollment period, you will need to visit our website and follow the steps provided for you. You will be required to provide your personal information such as name, date of birth, and social insurance number (SIN). Once you have completed these steps, you will receive an email confirmation with your Flex Benefit account details. If you have any questions or concerns about the enrollment process, please contact our customer service team at [insert phone number or email address].\n",
            "Query:  Am I able to make any updates to my coverage of flex benefits?\n",
            "Response:   To update your coverage of flexible benefits, you need to contact the Benefits Administration team at Rogers HR Connect | Connexion RH. They will guide you through the process and ensure that your changes are implemented correctly.\n",
            "Query:  who is eligible for the Legacy Shaw Employee Account Program?\n",
            "Response:   The Legacy Shaw Employee Account Program is available to all current and former employees of Rogers Communications who meet the eligibility criteria. Eligibility criteria includes being a permanent employee as of January 1, 2021, having completed at least one year of continuous employment with Rogers, and meeting the minimum age requirement. If you have any further questions or concerns, please contact our HR team at [insert phone number or email address].\n",
            "Query:  How do I get support with my Employee Account and Services\n",
            "Response:   To access support for your employee account and services, please follow the steps provided in our Service Portal - HR Connect | Connexion RH Loading. These steps will guide you through the process of resetting your password or accessing your account information. If you have any further questions or concerns, please do not hesitate to contact us at [insert phone number/email address]. Thank you for choosing Rogers Communications!\n"
          ]
        }
      ],
      "source": [
        "#role change \n",
        "#wrong answers on HR connect, maybe due to access issue, since only one chunk detected for the first url\n",
        "new_chat_bot = OpenSourceApp()\n",
        "\n",
        "webpage_url_2 = 'https://rogers2.service-now.com/hrportal?id=dynamic_hr_article&sys_id=5e99629a1b8701104cd7a8a8b04bcb2e'\n",
        "new_chat_bot.add('web_page', webpage_url_2)\n",
        "webpage_url_3 = 'https://www.rogerszone.ca/en-ca/ourrogers/DiscountsOffers/Pages/Legacy-Shaw-Employee-Account-Program.aspx'\n",
        "new_chat_bot.add('web_page', webpage_url_3)\n",
        "\n",
        "\n",
        "chatbot_template = Template(\"\"\"\n",
        "        You are an internal service agent serving for the employees of Rogers Communications. \\\n",
        "\n",
        "        Use the following material provided by Rogers Communications to respond to \n",
        "        the employee's query acting as an internal service agent. \\\n",
        "\n",
        "        Context: $context                              \n",
        "\n",
        "        Keep the response brief and only use the information given by the context. \\\n",
        "        If you don't know the answer, just say that you don't know, don't ever try to make up an answer. \\\n",
        "\n",
        "        Employee: $query \n",
        "        Internal service agent:\"\"\")\n",
        "query_config = QueryConfig(chatbot_template)\n",
        "queries = [\n",
        "        \"During the enrollment period of the Flex Benefits, what do I need to do?\",\n",
        "        \"Am I able to make any updates to my coverage of flex benefits?\",\n",
        "        \"who is eligible for the Legacy Shaw Employee Account Program?\",\n",
        "        \"How do I get support with my Employee Account and Services\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "        response = new_chat_bot.query(query, query_config)\n",
        "        print(\"Query: \", query)\n",
        "        print(\"Response: \", response)\n",
        "#wrong answers for all questions being generated even though told it to say no when encountering uncertainty \n",
        "# the first two questions' source documentation was not included and indexed\n",
        "# while the last two questions are simply WRONG!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Possible solution\n",
        "### Better performance for PDF than websites, performance on websites varies according to page complexity and some have access issue resulting unsucessful retrival of knowledge.    \n",
        "### Recommend for websites:    \n",
        "### 1. convert to other format such as pdf    \n",
        "### 2. if using websites format always prepare q&a pairs to check validity after websites being ingested   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading open source embedding model. This may take some time...\n",
            "Successfully loaded open source embedding model.\n",
            "Successfully saved Legacy_Shaw_Employee_Account_Program.pdf. Total chunks count: 17\n",
            "Query:  During the enrollment period of the Flex Benefits, what do I need to do?\n",
            "Response:   You will need to complete the Shaw Discount Enrollment form and submit your request to Shaw’s Employee Services (mailto:employee.services@sjrb.ca) by emailing employee.services@sj 3.\n",
            "Query:  Am I able to make any updates to my coverage of flex benefits?\n",
            "Response:   Yes, you can update your flex benefits coverage by contacting our HR department at (555) 123-4567. They will guide you through the process and provide you with the necessary forms to sign and return. Please note that some changes may require a waiting period before they take effect.\n",
            "Query:  Who is eligible to receive the Employee Service discounts? Do services have to be only at my home?\n",
            "Response:   All regular full-time and part-time team members are eligible to participate in the Employee Discount Program. Some exclusions may apply, but employees can receive discounts on their home phone service, internet service, and cable TV service if they choose to use those services outside of Rogers or Shaw. Your name and address on your Rogers account will need to match the name and address on your HR records. Multiple employees living at the same address are all eligible for individual discounted service.\n",
            "Query:  How long will a new package take to get set up? Will I require an installation appointment? \n",
            "Response:   The Employee Services team strives to get a response back to you within 1-3 business days after you send in your request and/or Enrollment Form. If you already have Shaw services and hardware at your address, no installation appointment is necessary. However, if you are a new Shaw customer, adding a core service to your account or moving over to the BlueCurve system, an appointment may be required, and the Employee Services team will con���rm a date and time that works best for you.\n"
          ]
        }
      ],
      "source": [
        "#role change \n",
        "#wrong answers on HR connect, maybe due to access issue, since only one chunk detected for the first url\n",
        "new_chat_bot = OpenSourceApp()\n",
        "\n",
        "\n",
        "pdf_url_3 = 'Legacy_Shaw_Employee_Account_Program.pdf'\n",
        "new_chat_bot.add('pdf_file', pdf_url_3)\n",
        "\n",
        "\n",
        "chatbot_template = Template(\"\"\"\n",
        "        You are an internal service agent serving for the employees of Rogers Communications. \\\n",
        "\n",
        "        Use the following material provided by Rogers Communications to respond to \n",
        "        the employee's query acting as an internal service agent. \\\n",
        "\n",
        "        Context: $context                              \n",
        "\n",
        "        Keep the response brief and only use the information given by the context. \\\n",
        "        If you don't know the answer, just say that you don't know, don't ever try to make up an answer. \\\n",
        "\n",
        "        Employee: $query \n",
        "        Internal service agent:\"\"\")\n",
        "query_config = QueryConfig(chatbot_template)\n",
        "queries = [\n",
        "        \"During the enrollment period of the Flex Benefits, what do I need to do?\",\n",
        "        \"Am I able to make any updates to my coverage of flex benefits?\",\n",
        "        \"Who is eligible to receive the Employee Service discounts? Do services have to be only at my home?\",\n",
        "        \"How long will a new package take to get set up? Will I require an installation appointment? \"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "        response = new_chat_bot.query(query, query_config)\n",
        "        print(\"Query: \", query)\n",
        "        print(\"Response: \", response)\n",
        "# the first two questions should output 'i do not know' since relevant context was not given (HR connect)\n",
        "# However for the last two are accurate with complete alignment with the source documentation (website to pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading open source embedding model. This may take some time...\n",
            "Successfully loaded open source embedding model.\n",
            "Successfully saved Legacy_Shaw_Employee_Account_Program.pdf. Total chunks count: 17\n",
            "Query:  During the enrollment period of the Flex Benefits, what do I need to do?\n",
            "Response:   To enroll in the Flex Benefits, please complete the Shaw Discount Enrollment form and submit your request to Shaw’s Employee Services (mailto:employee.services@sjrb.ca) by emailing employee.services@sj 3.\n",
            "Query:  Am I able to make any updates to my coverage of flex benefits?\n",
            "Response:   Yes, you can update your flex benefits coverage by contacting our HR department at (555) 123-4567 or emailing them at employee.services@sjrb.ca. They will be able to assist you with any questions or changes you may need to make.\n",
            "Query:  Who is eligible to receive the Employee Service discounts? Do services have to be only at my home?\n",
            "Response:   All regular full-time and part-time team members are eligible to participate in the Employee Discount Program. However, some exclusions may apply. While participating in the program, we ask team members not to purchase competing wireless, cable, internet, or home phone products if a Rogers product is available (outside of Rogers or Shaw). Your name and address on your Rogers account will need to match the name and address on your HR records. Multiple employees living at the same address are all eligible for individual discounted service. Services included with Shaw Discount Shaw Discount Enrollment Form (https://rcirogers.sharepoint.com/sites/rogerszone/en-ca/ourrogers/DiscountsOffers/SiteAssets/Employee%20Services%20Enrollment%20Form%20for%20Rogers%20Employees.pdf) Shaw Discount Packaging and \n",
            "\n",
            "    \n",
            "Query:  How long will a new package take to get set up? Will I require an installation appointment? \n",
            "Response:   The Employee Services team strives to get a response back to you within 1-3 business days after you send in your request and/or Enrollment Form. If you already have Shaw services and hardware at your address, no installation appointment is necessary. However, if you are a new Shaw customer, adding a core service to your account or moving over to the BlueCurve system, an appointment may be required, and the Employee Services team will con���rm a date and time that works best for you.\n"
          ]
        }
      ],
      "source": [
        "#the prompt is being adjusted to try to fix previous problems, however hallucinations still appears\n",
        "new_chat_bot = OpenSourceApp()\n",
        "\n",
        "\n",
        "pdf_url_3 = 'Legacy_Shaw_Employee_Account_Program.pdf'\n",
        "new_chat_bot.add('pdf_file', pdf_url_3)\n",
        "\n",
        "\n",
        "chatbot_template = Template(\"\"\"\n",
        "        You are an internal service agent serving for the employees of Rogers Communications. \\\n",
        "\n",
        "        Use the following material provided by Rogers Communications to respond to \n",
        "        the employee's query acting as an internal service agent. \\\n",
        "\n",
        "        Context: $context                              \n",
        "\n",
        "        Keep the response brief and only use the information given by the context. \\\n",
        "        If you don't know the answer, just say that you don't know, don't ever try to make up an answer. \\\n",
        "            \n",
        "        If the question is not related to the context, politely respond that you are tuned to only answer questions that are related to the context.\\\n",
        "\n",
        "\n",
        "        Employee: $query \n",
        "        Internal service agent:\"\"\")\n",
        "query_config = QueryConfig(chatbot_template)\n",
        "queries = [\n",
        "        \"During the enrollment period of the Flex Benefits, what do I need to do?\",\n",
        "        \"Am I able to make any updates to my coverage of flex benefits?\",\n",
        "        \"Who is eligible to receive the Employee Service discounts? Do services have to be only at my home?\",\n",
        "        \"How long will a new package take to get set up? Will I require an installation appointment? \"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "        response = new_chat_bot.query(query, query_config)\n",
        "        print(\"Query: \", query)\n",
        "        print(\"Response: \", response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Could also use openai embeddings and chatgpt, but perfomance may not vary much (tested through experimentation on OPENCHAT platform which uses openai api and embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\yuncheng.liang\\Documents\\GitHub\\chatgpt-langchain_practice\\基于Embedchain的AI对话机器人.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# Example: define your own chunker config for `youtube_video`\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# youtube_add_config = {\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m#         \"chunker\": {\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# webpage_url_2 = 'https://rogers2.service-now.com/hrportal?id=dynamic_hr_article&sys_id=5e99629a1b8701104cd7a8a8b04bcb2e'\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# open_ai_chat_bot.add('web_page', webpage_url_2)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m webpage_url_3 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://www.rogerszone.ca/en-ca/ourrogers/DiscountsOffers/Pages/Legacy-Shaw-Employee-Account-Program.aspx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m open_ai_chat_bot\u001b[39m.\u001b[39;49madd(\u001b[39m'\u001b[39;49m\u001b[39mweb_page\u001b[39;49m\u001b[39m'\u001b[39;49m, webpage_url_3)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m chatbot_template \u001b[39m=\u001b[39m Template(\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m        You are an internal service agent serving for the employees of Rogers Communications. \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m        Employee: $query \u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m        Internal service agent:\u001b[39m\u001b[39m\"\"\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yuncheng.liang/Documents/GitHub/chatgpt-langchain_practice/%E5%9F%BA%E4%BA%8EEmbedchain%E7%9A%84AI%E5%AF%B9%E8%AF%9D%E6%9C%BA%E5%99%A8%E4%BA%BA.ipynb#Y132sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m query_config \u001b[39m=\u001b[39m QueryConfig(chatbot_template)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\embedchain\\embedchain.py:56\u001b[0m, in \u001b[0;36mEmbedChain.add\u001b[1;34m(self, data_type, url, config)\u001b[0m\n\u001b[0;32m     54\u001b[0m data_formatter \u001b[39m=\u001b[39m DataFormatter(data_type)\n\u001b[0;32m     55\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_asks\u001b[39m.\u001b[39mappend([data_type, url])\n\u001b[1;32m---> 56\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_and_embed(data_formatter\u001b[39m.\u001b[39;49mloader, data_formatter\u001b[39m.\u001b[39;49mchunker, url)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\embedchain\\embedchain.py:105\u001b[0m, in \u001b[0;36mEmbedChain.load_and_embed\u001b[1;34m(self, loader, chunker, src)\u001b[0m\n\u001b[0;32m    102\u001b[0m     ids \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(data_dict\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m    103\u001b[0m     documents, metadatas \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mdata_dict\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m--> 105\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollection\u001b[39m.\u001b[39;49madd(\n\u001b[0;32m    106\u001b[0m     documents\u001b[39m=\u001b[39;49mdocuments,\n\u001b[0;32m    107\u001b[0m     metadatas\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(metadatas),\n\u001b[0;32m    108\u001b[0m     ids\u001b[39m=\u001b[39;49mids\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    110\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSuccessfully saved \u001b[39m\u001b[39m{\u001b[39;00msrc\u001b[39m}\u001b[39;00m\u001b[39m. Total chunks count: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcollection\u001b[39m.\u001b[39mcount()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\chromadb\\api\\models\\Collection.py:96\u001b[0m, in \u001b[0;36mCollection.add\u001b[1;34m(self, ids, embeddings, metadatas, documents, increment_index)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd\u001b[39m(\n\u001b[0;32m     70\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     71\u001b[0m     ids: OneOrMany[ID],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     75\u001b[0m     increment_index: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     76\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[39m\"\"\"Add embeddings to the data store.\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[39m        ids: The ids of the embeddings you wish to add\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 96\u001b[0m     ids, embeddings, metadatas, documents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_embedding_set(\n\u001b[0;32m     97\u001b[0m         ids, embeddings, metadatas, documents\n\u001b[0;32m     98\u001b[0m     )\n\u001b[0;32m    100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39m_add(\n\u001b[0;32m    101\u001b[0m         ids, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid, embeddings, metadatas, documents, increment_index\n\u001b[0;32m    102\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\chromadb\\api\\models\\Collection.py:390\u001b[0m, in \u001b[0;36mCollection._validate_embedding_set\u001b[1;34m(self, ids, embeddings, metadatas, documents, require_embeddings_or_documents)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must provide embeddings or a function to compute them\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         )\n\u001b[1;32m--> 390\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function(documents)\n\u001b[0;32m    392\u001b[0m \u001b[39m# if embeddings is None:\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[39m#     raise ValueError(\u001b[39;00m\n\u001b[0;32m    394\u001b[0m \u001b[39m#         \"Something went wrong. Embeddings should be computed at this point\"\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[39m#     )\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[39mreturn\u001b[39;00m ids, embeddings, metadatas, documents\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\chromadb\\utils\\embedding_functions.py:121\u001b[0m, in \u001b[0;36mOpenAIEmbeddingFunction.__call__\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    118\u001b[0m texts \u001b[39m=\u001b[39m [t\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m texts]\n\u001b[0;32m    120\u001b[0m \u001b[39m# Call the OpenAI Embedding API\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtexts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model_name)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    123\u001b[0m \u001b[39m# Sort resulting embeddings by index\u001b[39;00m\n\u001b[0;32m    124\u001b[0m sorted_embeddings \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(embeddings, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m e: e[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m])  \u001b[39m# type: ignore\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\yuncheng.liang\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
            "File \u001b[1;32mc:\\Users\\yuncheng.liang\\Anaconda3\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[1;32mc:\\Users\\yuncheng.liang\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
            "File \u001b[1;32mc:\\Users\\yuncheng.liang\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    614\u001b[0m         )\n\u001b[0;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    624\u001b[0m         ),\n\u001b[0;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    626\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\yuncheng.liang\\Anaconda3\\lib\\site-packages\\openai\\api_requestor.py:682\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    680\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    681\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    683\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
            "\u001b[1;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details."
          ]
        }
      ],
      "source": [
        "import os\n",
        "from embedchain import App\n",
        "from embedchain.config import InitConfig, AddConfig, QueryConfig\n",
        "from chromadb.utils import embedding_functions\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "# Example: use your own embedding function\n",
        "# config = InitConfig(ef=embedding_functions.OpenAIEmbeddingFunction(\n",
        "#                 api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "#                 organization_id=os.getenv(\"OPENAI_ORGANIZATION\"),\n",
        "#                 model_name=\"text-embedding-ada-002\"\n",
        "#             ))\n",
        "config = InitConfig(ef=embedding_functions.OpenAIEmbeddingFunction(\n",
        "                api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
        "                model_name=\"text-embedding-ada-002\"\n",
        "            ))\n",
        "open_ai_chat_bot = App(config)\n",
        "\n",
        "# Example: define your own chunker config for `youtube_video`\n",
        "# youtube_add_config = {\n",
        "#         \"chunker\": {\n",
        "#                 \"chunk_size\": 1000,\n",
        "#                 \"chunk_overlap\": 100,\n",
        "#                 \"length_function\": len,\n",
        "#         }\n",
        "# }\n",
        "# naval_chat_bot.add(\"youtube_video\", \"https://www.youtube.com/watch?v=3qHkcs3kG44\", AddConfig(**youtube_add_config))\n",
        "\n",
        "# add_config = AddConfig()\n",
        "# naval_chat_bot.add(\"pdf_file\", \"https://navalmanack.s3.amazonaws.com/Eric-Jorgenson_The-Almanack-of-Naval-Ravikant_Final.pdf\", add_config)\n",
        "# naval_chat_bot.add(\"web_page\", \"https://nav.al/feedback\", add_config)\n",
        "# naval_chat_bot.add(\"web_page\", \"https://nav.al/agi\", add_config)\n",
        "\n",
        "# naval_chat_bot.add_local(\"qna_pair\", (\"Who is Naval Ravikant?\", \"Naval Ravikant is an Indian-American entrepreneur and investor.\"), add_config)\n",
        "\n",
        "\n",
        "\n",
        "# webpage_url_2 = 'https://rogers2.service-now.com/hrportal?id=dynamic_hr_article&sys_id=5e99629a1b8701104cd7a8a8b04bcb2e'\n",
        "# open_ai_chat_bot.add('web_page', webpage_url_2)\n",
        "webpage_url_3 = 'https://www.rogerszone.ca/en-ca/ourrogers/DiscountsOffers/Pages/Legacy-Shaw-Employee-Account-Program.aspx'\n",
        "open_ai_chat_bot.add('web_page', webpage_url_3)\n",
        "\n",
        "\n",
        "chatbot_template = Template(\"\"\"\n",
        "        You are an internal service agent serving for the employees of Rogers Communications. \\\n",
        "\n",
        "        Use the following material provided by Rogers Communications to respond to \n",
        "        the employee's query acting as an internal service agent. \\\n",
        "\n",
        "        Context: $context                              \n",
        "\n",
        "        Keep the response brief and only use the information given by the context. \\\n",
        "        If you don't know the answer, just say that you don't know, don't ever try to make up an answer. \\\n",
        "\n",
        "        Employee: $query \n",
        "        Internal service agent:\"\"\")\n",
        "query_config = QueryConfig(chatbot_template)\n",
        "queries = [\n",
        "        \"who is eligible for the Legacy Shaw Employee Account Program?\",\n",
        "        \"How do I get support with my Employee Account and Services\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "        response = open_ai_chat_bot.query(query, query_config)\n",
        "        print(\"Query: \", query)\n",
        "        print(\"Response: \", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Choose your level of coverage:\n",
        "\n",
        "# Team Member Only\n",
        "# Team Member + 1 eligible dependent, or\n",
        "# Team Member + 2 or more eligible dependents\n",
        "# 2. Personalize your benefits coverage to fit the unique needs of you and your family.\n",
        "\n",
        "# 3. Use your flex credits and/or payroll dollars to purchase increased coverage.\n",
        "\n",
        "# 4. Allocate your excess flex credits (if applicable) to your Health Spending Account, Personal Spending Account, Global RRSP and the Rogers TFSA to be used as needed.\n",
        "\n",
        "# 5. Review or complete your beneficiary and trustee designation.\n",
        "\n",
        "\n",
        "\n",
        "#Outside of the annual enrollment period or an eligible life event, you are not able to make any updates to your coverage.\n",
        "\n",
        "\n",
        "\n",
        "# Who is eligible?  \n",
        "# All regular full-time and part-time team members are eligible to participate in the Employee Discount Program. Some exclusions may apply.  \n",
        "# While participating in the program, we ask team members not to purchase competing wireless, cable, internet, or home phone products if a Rogers product is available (outside of Rogers or Shaw).  \n",
        "# Your name and address on your Rogers account will need to match the name and address on your HR records.  \n",
        "# Multiple employees living at the same address are all eligible for individual discounted service. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "biO6XrfN5A2O"
      },
      "source": [
        "## Embedchain原理\n",
        "\n",
        "https://github.com/embedchain/embedchain#how-does-it-work\n",
        "\n",
        "![](https://zihao-code.obs.cn-east-3.myhuaweicloud.com/20230706-embedchain/1.png)\n",
        "\n",
        "![](https://zihao-code.obs.cn-east-3.myhuaweicloud.com/20230706-embedchain/2.pic.jpg)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rTQPPVRVrVc1"
      },
      "source": [
        "## 思考与扩展\n",
        "\n",
        "- 尝试更换不同的语料库（视频、网页、PDF）\n",
        "\n",
        "- 如何对中文语料库做类似的问答机器人？\n",
        "\n",
        "- 简述embedchain算法流程\n",
        "\n",
        "- 整个问答对话流程中，需要几个AI模型，分别起什么作用？\n",
        "\n",
        "- 整个问答对话流程中，大语言模型起到什么作用？更换不同的大语言模型，对话效果有何差异？\n",
        "\n",
        "- 通过提示词调优，修改AI的人设，让它变得严谨，或者活泼。\n",
        "\n",
        "- 尝试不同的数据块chunk大小"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_vVkZH_9sfDZ"
      },
      "source": [
        "## 参考文档\n",
        "\n",
        "https://github.com/embedchain/embedchain\n",
        "\n",
        "https://www.youtube.com/watch?v=qj_GNQ06I8o"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWy17Dlap4MA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
